{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ea7a9ed2fbe7dc85\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ea7a9ed2fbe7dc85\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6009;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /workspace/tf_native/results/event_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>All Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Op Name</th>\n",
       "      <th>Op Type</th>\n",
       "      <th>No. Calls</th>\n",
       "      <th>TC Eligible</th>\n",
       "      <th>Using TC</th>\n",
       "      <th>Total CPU Time (ns)</th>\n",
       "      <th>Avg. CPU Time (ns)</th>\n",
       "      <th>Min CPU Time (ns)</th>\n",
       "      <th>Max CPU Time (ns)</th>\n",
       "      <th>Total GPU Time (ns)</th>\n",
       "      <th>Avg. GPU Time (ns)</th>\n",
       "      <th>Min GPU Time (ns)</th>\n",
       "      <th>Max GPU Time (ns)</th>\n",
       "      <th>Total CPU Overhead (ns)</th>\n",
       "      <th>Avg. CPU Overhead (ns)</th>\n",
       "      <th>Min CPU Overhead (ns)</th>\n",
       "      <th>Max CPU Overhead (ns)</th>\n",
       "      <th>Total GPU Idle (ns)</th>\n",
       "      <th>Avg. GPU Idle (ns)</th>\n",
       "      <th>Min GPU Idle (ns)</th>\n",
       "      <th>Max GPU Idle (ns)</th>\n",
       "      <th>Data Type</th>\n",
       "      <td>Input Shapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Add</th>\n",
       "      <th>Add</th>\n",
       "      <th>1010</th>\n",
       "      <th>no</th>\n",
       "      <th>no</th>\n",
       "      <th>27264798</th>\n",
       "      <th>26994.8</th>\n",
       "      <th>17966</th>\n",
       "      <th>202025</th>\n",
       "      <th>2750116</th>\n",
       "      <th>2722.9</th>\n",
       "      <th>2495</th>\n",
       "      <th>14784</th>\n",
       "      <th>12149221</th>\n",
       "      <th>12028.9</th>\n",
       "      <th>7746</th>\n",
       "      <th>131785</th>\n",
       "      <th>0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>float32</th>\n",
       "      <td>MatMul: &lt;100, 500&gt;, Variable_2/read: &lt;500&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientDescent/GradientDescent/-apply</th>\n",
       "      <th>NoOp</th>\n",
       "      <th>1010</th>\n",
       "      <th>no</th>\n",
       "      <th>no</th>\n",
       "      <th>3471225</th>\n",
       "      <th>3436.9</th>\n",
       "      <th>2625</th>\n",
       "      <th>21267</th>\n",
       "      <th>0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>3471225</th>\n",
       "      <th>3436.9</th>\n",
       "      <th>2625</th>\n",
       "      <th>21267</th>\n",
       "      <th>0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientDescent/learning_rate</th>\n",
       "      <th>Const</th>\n",
       "      <th>1011</th>\n",
       "      <th>no</th>\n",
       "      <th>no</th>\n",
       "      <th>2724431</th>\n",
       "      <th>2694.8</th>\n",
       "      <th>1394</th>\n",
       "      <th>22408</th>\n",
       "      <th>0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>2724431</th>\n",
       "      <th>2694.8</th>\n",
       "      <th>1394</th>\n",
       "      <th>22408</th>\n",
       "      <th>0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientDescent/update_Variable/ApplyGradientDescent</th>\n",
       "      <th>ApplyGradientDescent</th>\n",
       "      <th>1010</th>\n",
       "      <th>no</th>\n",
       "      <th>no</th>\n",
       "      <th>11297316</th>\n",
       "      <th>11185.5</th>\n",
       "      <th>9684</th>\n",
       "      <th>28974</th>\n",
       "      <th>2369156</th>\n",
       "      <th>2345.7</th>\n",
       "      <th>2303</th>\n",
       "      <th>2848</th>\n",
       "      <th>4156918</th>\n",
       "      <th>4115.8</th>\n",
       "      <th>3526</th>\n",
       "      <th>21333</th>\n",
       "      <th>0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>float32</th>\n",
       "      <td>Variable: &lt;10, 500&gt;, gradients/MatMul_grad/Mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 All Iterations\n",
       "Op Name                                            Op Type              No. Calls TC Eligible Using TC Total CPU Time (ns) Avg. CPU Time (ns) Min CPU Time (ns) Max CPU Time (ns) Total GPU Time (ns) Avg. GPU Time (ns) Min GPU Time (ns) Max GPU Time (ns) Total CPU Overhead (ns) Avg. CPU Overhead (ns) Min CPU Overhead (ns) Max CPU Overhead (ns) Total GPU Idle (ns) Avg. GPU Idle (ns) Min GPU Idle (ns) Max GPU Idle (ns) Data Type                                       Input Shapes\n",
       "Add                                                Add                  1010      no          no       27264798            26994.8            17966             202025            2750116             2722.9             2495              14784             12149221                12028.9                7746                  131785                0                   0.0                0                 0                 float32           MatMul: <100, 500>, Variable_2/read: <500>\n",
       "GradientDescent/GradientDescent/-apply             NoOp                 1010      no          no       3471225             3436.9             2625              21267             0                   0.0                0                 0                 3471225                 3436.9                 2625                  21267                 0                   0.0                0                 0                 NaN                                                      NaN\n",
       "GradientDescent/learning_rate                      Const                1011      no          no       2724431             2694.8             1394              22408             0                   0.0                0                 0                 2724431                 2694.8                 1394                  22408                 0                   0.0                0                 0                 NaN                                                      NaN\n",
       "GradientDescent/update_Variable/ApplyGradientDe... ApplyGradientDescent 1010      no          no       11297316            11185.5            9684              28974             2369156             2345.7             2303              2848              4156918                 4115.8                 3526                  21333                 0                   0.0                0                 0                 float32    Variable: <10, 500>, gradients/MatMul_grad/Mat..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "detail=pd.read_csv('./results/simple_tf1_mlp_detailed.csv')\n",
    "detail.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------- must convert the below to a **xxx.py** file for DLprof to run -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "print(dataset.head())\n",
    "# find out how many records we have\n",
    "len(dataset)\n",
    "#find out how many columns we have\n",
    "len(dataset.columns)\n",
    "X = dataset.iloc[:, 3:13].values # python index does not include the last column=13\n",
    "\n",
    "type(X)\n",
    "y = dataset.iloc[:, 13].values # but do it this way, it will only take column 13\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(8000, 10)\n",
      "(8000,)\n",
      "(2000, 10)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling - in general, we need to always do feature scaling for neural network\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "records, input_num =X_train.shape\n",
    "input_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (8000, 10) (8000, 2)\n",
      "testing set (2000, 10) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 2\n",
    "# make the training dataset into 200000x 28*28 --> 20000 , 784\n",
    "def reformat(labels):\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return labels\n",
    "y_train = reformat(y_train)\n",
    "y_test = reformat(y_test)\n",
    "\n",
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('testing set', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.astype(np.float32)\n",
    "print(X_test.shape)\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# improve your nn by inserting one hidden layer\n",
    "num_steps = 1000 # hyper-parameter\n",
    "batch_size = 100 # another hyper-parameter\n",
    "train_subset = 8000 # in case your memory capacity is low\n",
    "\n",
    "num_labels=2\n",
    "\n",
    "# neural network with 1 hidden layer \n",
    "n_hidden_1 = 500 #  1st layer number of features, yet another hyper-parameter\n",
    "n_input = 10    #  data input (img shape: 28*28) since your input matrix shape is (train_subsetX28*28)=10000*784\n",
    "n_classes = 2    #  total classes 2:churn/not churn \n",
    "\n",
    "\n",
    "# Store layers weight & bias using python dictionary-like syntax\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_1, n_classes]))\n",
    "} # you can access hidden layer1=h1's matrix via weights['h1'] as well as output from activation function via weight['out']\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "    'out': tf.Variable(tf.zeros([n_classes]))\n",
    "}\n",
    "#print(\"shape of weight matrix h1: \", weights['h1'])\n",
    "#print(\"shape of weight matrix out : \", weights['out'])\n",
    "#print(\"shape of bias matrix b1 :\", biases['b1'])\n",
    "#print(\"shape of bias matrix out\", biases['out'])\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input]) # None means you can input dynamic amount of inputs images\n",
    "y = tf.placeholder(tf.float32, [None, n_classes]) \n",
    "#print(\"x is of shape :\", x)\n",
    "#print(\"y is of shape :\", y)\n",
    "\n",
    "\n",
    "tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, 10))\n",
    "tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "tf_valid_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(None, 10))\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    #print(\"shape of layer_1 matrix :\" ,layer_1)\n",
    "    layer_1 = tf.nn.relu(layer_1) \n",
    "          # activation function=rectifier , relu(features, name=none) same shape of the layer_1 matrix\n",
    "    #print(\"shape after activation function of layer 1: \", layer_1)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "    print(\"shape of out_layer matrix out of hidden layer --> out_layer :\" , out_layer)\n",
    "    return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of out_layer matrix out of hidden layer --> out_layer : Tensor(\"add_1:0\", shape=(?, 2), dtype=float32)\n",
      "shape of out_layer matrix out of hidden layer --> out_layer : Tensor(\"add_3:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Construct model \n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "valid_pred = multilayer_perceptron(tf_valid_dataset, weights, biases)\n",
    "\n",
    " \n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "      / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized tensorflow session\n",
      "Minibatch loss at step 0: 88.495857\n",
      "Minibatch accuracy: 32.0%\n",
      "test data accuracy: 79.8%\n",
      "Minibatch loss at step 100: 2.997778\n",
      "Minibatch accuracy: 83.0%\n",
      "test data accuracy: 83.0%\n",
      "Minibatch loss at step 200: 1.330644\n",
      "Minibatch accuracy: 87.0%\n",
      "test data accuracy: 84.9%\n",
      "Minibatch loss at step 300: 1.977455\n",
      "Minibatch accuracy: 72.0%\n",
      "test data accuracy: 83.8%\n",
      "Minibatch loss at step 400: 1.391028\n",
      "Minibatch accuracy: 79.0%\n",
      "test data accuracy: 84.5%\n",
      "Minibatch loss at step 500: 0.791865\n",
      "Minibatch accuracy: 78.0%\n",
      "test data accuracy: 84.1%\n",
      "Minibatch loss at step 600: 0.697800\n",
      "Minibatch accuracy: 83.0%\n",
      "test data accuracy: 75.2%\n",
      "Minibatch loss at step 700: 0.696401\n",
      "Minibatch accuracy: 78.0%\n",
      "test data accuracy: 83.8%\n",
      "Minibatch loss at step 800: 0.506471\n",
      "Minibatch accuracy: 85.0%\n",
      "test data accuracy: 85.0%\n",
      "Minibatch loss at step 900: 0.541145\n",
      "Minibatch accuracy: 79.0%\n",
      "test data accuracy: 85.5%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Initialized tensorflow session\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = X_train[offset:(offset + batch_size), :]\n",
    "        batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {x : batch_data, y : batch_labels}\n",
    "        _, l, predictions = sess.run([optimizer, loss, pred], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            test_dict={x:X_test, y: y_test}\n",
    "            _, l, testpred = sess.run([optimizer, loss, pred], feed_dict=test_dict)\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"test data accuracy: %.1f%%\" % accuracy(testpred, y_test))\n",
    "            \n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
